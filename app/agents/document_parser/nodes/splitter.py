from typing import List

from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter

from rich import print as rprint


def load_splitter():
    CHUNK_SIZE = 300
    CHUNK_OVERLAP = 50
    CHUNK_SEPARATOR = ["\n\n", "\n", ". ", " ", ""]

    # TODO: markdownì— íŠ¹í™”ëœ splitter?
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=CHUNK_SIZE,
        chunk_overlap=CHUNK_OVERLAP,
        separators=CHUNK_SEPARATOR,
        strip_whitespace=True,
    )
    # rprint(">>> splitter", splitter)

    return splitter


def split(dp_result: List[Document]) -> List[Document]:
    """
    split dp_result

    Args:
        dp_result

    Returns:
        chunks (List[Document]):
            - dp_resultë¥¼ splití•œ ê²°ê³¼
            - document["metadata"]["total_pages"]: ì›ë³¸ ë¬¸ì„œ(PDF)ì˜ ì „ì²´ í˜ì´ì§€ ìˆ˜
            - len(chunks): ì „ì²´ ë¬¸ì„œë¥¼ chunk sizeì™€ chunk overlapì„ ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆˆ ê²°ê³¼ì˜ ê°œìˆ˜
    """
    splitter = load_splitter()

    rprint("ğŸš€split documents start")
    chunks = splitter.split_documents(dp_result)
    rprint("âœ…split documents done. chunks length:", len(chunks))
    # rprint(">>> sample chunk", chunks[0])

    return chunks
