import argparse
import re
from pathlib import Path
from typing import List

from dotenv import load_dotenv

from langchain_core.documents import Document
from langchain_upstage.document_parse import OutputFormat
from langchain_upstage import UpstageDocumentParseLoader

from rich import print as rprint

load_dotenv()


def create_arg_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description="Run document parser graph.")
    parser.add_argument(
        "--file-name",
        help="PDF file name under app/agents/document_parser/data/terms",
    )
    return parser


def parse_document(
    file_name: str, output_format: OutputFormat = "html"
) -> List[Document]:
    # BASE_DIR = Path(os.getenv("PROJECT_ROOT", ".")).resolve() # project root
    BASE_DIR = Path(__file__).resolve().parent.parent  # app/agents/document_parser
    TERMS_DIR = BASE_DIR / "data" / "terms"
    TERM_FILE_PATH = TERMS_DIR / file_name
    rprint("ğŸ”—parse_document TERM_FILE_PATH:", TERM_FILE_PATH)

    dp_loader = UpstageDocumentParseLoader(
        file_path=str(TERM_FILE_PATH),
        output_format=output_format,
        coordinates=False,
    )
    # rprint(">>> dp_loader", dp_loader)

    rprint("ğŸš€document parsing start. output format:", output_format)
    dp_result = dp_loader.load()  # ì „ì²´ ë¬¸ì„œê°€ í•˜ë‚˜ì˜ Documentë¡œ ì¶”ì¶œë¨
    rprint("âœ…document parsing done. result length:", len(dp_result))  # 1

    create_local_file(dp_result, TERMS_DIR, file_name, output_format)

    return split_by_page_marker(dp_result[0])


def split_by_page_marker(full_document: Document) -> list[Document]:
    """
    Upstage Document Parse ê²°ê³¼(ì „ì²´ê°€ 1ê°œ Documentë¡œ ë“¤ì–´ì˜¨ í…ìŠ¤íŠ¸)ë¥¼
    í˜ì´ì§€ ë§ˆì»¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í˜ì´ì§€ ë‹¨ìœ„ Document ë¦¬ìŠ¤íŠ¸ë¡œ ë¶„ë¦¬í•œë‹¤.

    ê¸°ëŒ€í•˜ëŠ” ì…ë ¥ ì˜ˆ:
    - "... ì•½ê´€ ë³¸ë¬¸ ... - 1 - ... ë‹¤ìŒ ë³¸ë¬¸ ... - 2 - ..."

    ë°˜í™˜:
    - ê° í˜ì´ì§€ë¥¼ `Document(page_content=..., metadata={"page": n, ...})` í˜•íƒœë¡œ ë°˜í™˜
    - ì›ë³¸ metadataëŠ” ìœ ì§€í•˜ê³ , í˜ì´ì§€ ë²ˆí˜¸(`page`)ë§Œ ì¶”ê°€
    """

    # ì „ì²´ ë¬¸ì„œ í…ìŠ¤íŠ¸(ì—¬ëŸ¬ í˜ì´ì§€ê°€ í•˜ë‚˜ë¡œ í•©ì³ì§„ ë¬¸ìì—´)
    text = full_document.page_content

    # í˜ì´ì§€ ë§ˆì»¤ ì •ê·œì‹:
    # - "- 21 -" ê°™ì€ í˜•íƒœë¥¼ ì¸ì‹í•œë‹¤.
    # - (\d+) ìº¡ì²˜ ê·¸ë£¹ìœ¼ë¡œ í˜ì´ì§€ ë²ˆí˜¸ë§Œ ì¶”ì¶œí•œë‹¤.
    #   ì˜ˆ: "- 21 -" -> group(1) == "21"
    pattern = r"-\s*(\d+)\s*-"

    # ë¬¸ì„œ ì „ì²´ì—ì„œ í˜ì´ì§€ ë§ˆì»¤ ìœ„ì¹˜ë¥¼ ëª¨ë‘ ì°¾ëŠ”ë‹¤.
    # ê° matchì—ëŠ” "ë§ˆì»¤ ì‹œì‘/ë ì¸ë±ìŠ¤"ì™€ "í˜ì´ì§€ ë²ˆí˜¸ ë¬¸ìì—´"ì´ ë“¤ì–´ ìˆë‹¤.
    matches = list(re.finditer(pattern, text))
    rprint("ğŸ“‘total pages:", len(matches))

    # ë§ˆì»¤ë¥¼ í•˜ë‚˜ë„ ì°¾ì§€ ëª»í•˜ë©´ í˜ì´ì§€ ë¶„í• ì´ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ ì¦‰ì‹œ ì˜ˆì™¸ë¥¼ ë˜ì§„ë‹¤.
    if not matches:
        raise ValueError("â—ï¸í˜ì´ì§€ ë§ˆì»¤ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    page_docs = []

    # ê° í˜ì´ì§€ ë§ˆì»¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ "í˜„ì¬ ë§ˆì»¤ ë ~ ë‹¤ìŒ ë§ˆì»¤ ì‹œì‘" êµ¬ê°„ì„ ì˜ë¼ì„œ
    # í˜ì´ì§€ ë³¸ë¬¸ìœ¼ë¡œ ë§Œë“ ë‹¤.
    for i, match in enumerate(matches):
        # ì •ê·œì‹ ìº¡ì²˜ ê·¸ë£¹ì—ì„œ í˜ì´ì§€ ë²ˆí˜¸ë¥¼ êº¼ë‚´ ì •ìˆ˜ë¡œ ë³€í™˜
        page_number = int(match.group(1))

        # start: í˜„ì¬ í˜ì´ì§€ ë§ˆì»¤ ë°”ë¡œ ë’¤ë¶€í„° ë³¸ë¬¸ ì‹œì‘
        start = match.end()
        # end:
        # - ë‹¤ìŒ ë§ˆì»¤ê°€ ìˆìœ¼ë©´ ê·¸ ì§ì „ê¹Œì§€
        # - ë§ˆì§€ë§‰ í˜ì´ì§€ë©´ ë¬¸ì„œ ëê¹Œì§€
        end = matches[i + 1].start() if i + 1 < len(matches) else len(text)

        # ì•ë’¤ ê³µë°±/ê°œí–‰ ì •ë¦¬
        page_text = text[start:end].strip()

        # í˜ì´ì§€ ë‹¨ìœ„ Document ìƒì„±
        # - ì›ë³¸ metadataëŠ” ê·¸ëŒ€ë¡œ ë³µì‚¬(**full_doc.metadata)
        # - page ë²ˆí˜¸ë¥¼ ì¶”ê°€í•´ downstream(ì²­í‚¹/íƒœê¹…/ì¸ë±ì‹±)ì—ì„œ í™œìš© ê°€ëŠ¥í•˜ê²Œ í•¨
        page_docs.append(
            Document(
                page_content=page_text,
                metadata={
                    **full_document.metadata,
                    "page": page_number,
                },
            )
        )

    # í˜ì´ì§€ ìˆœì„œëŒ€ë¡œ ë¶„ë¦¬ëœ Document ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    return page_docs


def create_local_file(
    dp_result: List[Document],
    target_dir: Path,
    original_file_name: str,
    output_format: OutputFormat = "html",
):
    if not dp_result:
        raise ValueError("Document parse result is empty.")

    output_extension_by_format = {
        "html": "html",
        "text": "txt",
        "markdown": "md",
    }
    OUTPUT_EXTENSION = output_extension_by_format.get(output_format)
    if OUTPUT_EXTENSION is None:
        raise ValueError(f"Unsupported output_format: {output_format}")
    rprint("OUTPUT_EXTENSION:", OUTPUT_EXTENSION)

    OUTPUT_FILE_NAME = f"{Path(original_file_name).stem}_dp_content.{OUTPUT_EXTENSION}"
    OUTPUT_FILE_PATH = target_dir / OUTPUT_FILE_NAME
    rprint("ğŸ”—create_local_file OUTPUT_FILE_PATH:", OUTPUT_FILE_PATH)

    if OUTPUT_FILE_PATH.exists():
        rprint("âš ï¸ create_local_file skipped (already exists)")
        return

    dp_content = dp_result[0].page_content
    # rprint(">>> dp_content", dp_content)

    rprint("ğŸš€create_local_file start")
    OUTPUT_FILE_PATH.write_text(dp_content, encoding="utf-8")
    rprint("âœ…create_local_file done")


if __name__ == "__main__":
    args = create_arg_parser().parse_args()
    file_name = args.file_name
    parse_document(file_name)


# uv run python -m app.agents.document_parser.nodes.document_parse --file-name meritz_maum_pet_12_16.pdf
